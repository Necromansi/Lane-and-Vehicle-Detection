{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7327ce1a-e849-404a-a21d-ef8ea0e0daa1",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Vehicle Detection Software</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dcec50-5cce-4012-880d-5b7ff4dbd3af",
   "metadata": {},
   "source": [
    "This project was prepared by:\n",
    "\n",
    "1. Youssef Nasser ElSayed Mohamed ID: 1701760\n",
    "2. Youssef Mohamed Mohamed Mansi ID: 1701754\n",
    "3. Youssef Ayman Mohamed Hassan ID: 1701708"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7060f-0d35-4201-bb17-6f9c8935c428",
   "metadata": {},
   "source": [
    "This software was done using the following libraries:\n",
    "- OpenCV\n",
    "- Matplotlib\n",
    "- Numpy\n",
    "- MoviePy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e7bcf-38a4-4d9e-9847-5e9beb44ee50",
   "metadata": {},
   "source": [
    "## <font color=green>The pipeline is as follows:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867bf4ec-335f-45cf-8c1a-db68ce3a08d6",
   "metadata": {},
   "source": [
    "- Perform a Histogram of oriented gradients (HOG) feature extraction on a set of images\n",
    "- Train a Linear SVM classifier.\n",
    "- Implement a sliding windows technique, and identify the vehicles in the video.\n",
    "- Run the pipeline on the video and create a heatmap of recurring detections.\n",
    "- Make a heat threshold\n",
    "- Estimate a bounding box for the vehicles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe3dd2f-2672-4771-bbd0-7544d8393f6d",
   "metadata": {},
   "source": [
    "## HOG Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f29099-3c7e-4db0-87dc-206fba56b6d3",
   "metadata": {},
   "source": [
    "In the first phase of the project, we perform HOG feature extraction on a set of labeled test images, labeled as vehicles and non-vehicles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24549e5-9050-480e-b9ec-4b500662f263",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <th><img src=\"kiti1.png\" width = 150></th>\n",
    "    <th><img src=\"kiti2.png\" width = 150></th>\n",
    "    <th><img src=\"kiti3.png\" width = 150></th>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f938b-dd9e-4bc7-9ff5-3fbfa1e45b20",
   "metadata": {},
   "source": [
    "<center> HOG Feature Extraction </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4432f702-56d9-417a-b278-52825a1f1d41",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <th><img src=\"carex1.png\" width = 150></th>\n",
    "    <th><img src=\"carex2.png\" width = 150></th>\n",
    "    <th><img src=\"carex3.png\" width = 150></th>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22a7aa2-cdd4-49b6-808a-6fddcfd435fc",
   "metadata": {},
   "source": [
    "<center> Examples of cars from the training set of images.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fbfab5-0371-405e-8c28-64044aa85926",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <th><img src=\"nocarex1.png\" width = 150></th>\n",
    "    <th><img src=\"nocarex2.png\" width = 150></th>\n",
    "    <th><img src=\"nocarex3.png\" width = 150></th>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa8b07c-c42e-492c-bab9-cd37e6e227eb",
   "metadata": {},
   "source": [
    "<center> Examples of non-vehicles in the training set of images </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b6d25-f764-4eb3-b389-4965ad7f0f6c",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692f630f-e680-424e-bede-35a5dbc55baa",
   "metadata": {},
   "source": [
    "## Training the SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fcf3f7-5078-4188-b1bd-394308c73e79",
   "metadata": {},
   "source": [
    "In this phase, we train the SVM Classifier using the HOG features we obtained from the first phase, and using a YCrCb Color space for more accuracy. We used only 2760 images for training the SVM Classifier for better memory and speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b860d1-4a7c-47fd-ae6d-2b9b7a77ef6b",
   "metadata": {},
   "source": [
    "#### Reasons for using the SVM Classifier:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af2e54-096d-4488-afc4-5893bbf90bfc",
   "metadata": {},
   "source": [
    "- Effective in high dimensional spaces.\n",
    "- Doesn't use a huge amount of memory.\n",
    "- Very versatile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d99ab85-0aa5-4b8e-9039-ba93a67b7280",
   "metadata": {},
   "source": [
    "We could have used SSD method (Single Shot Detector) which is more accurate, but it was very difficult to implement in this project, and we found that the SVM Classifier did an okay job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a9ad9-5d85-4f5d-8327-644309244f46",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a996f2-f83d-4b3c-85bf-26f463efd35f",
   "metadata": {},
   "source": [
    "## Sliding Window Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e20ad4-5851-4e6f-91e5-fc29746d4f0c",
   "metadata": {},
   "source": [
    "In this phase, we also implement a sliding window search as we did in the lane detection phase. The sliding window technique is the most commonly used method of pixel detection in image processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc30659d-e87f-453d-9a3d-4b33091ffba3",
   "metadata": {},
   "source": [
    "<center><img src=\"slidingphaseone.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313ae87c-41ab-477a-9cfd-78278abf6a85",
   "metadata": {},
   "source": [
    "<center> Sliding windows technique in phase one ( Lane Lines ) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366d284d-31f0-4e7e-8a5b-cbc495901bdf",
   "metadata": {},
   "source": [
    "The problem in the sliding window search is that it consumes so much time, so we start the scaling of the image from 0.8 to 1.5 . The window then slides from top to bottom and left to right. The windows overlap to increase accuracy. It then selects the rectangles with a minimum number of pixels inside."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea04bd90-9633-4ddb-ad3a-c7db6e8db252",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cadf3a0-64b7-41d3-b083-c62589f0111b",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803e60d-9c31-489c-be5e-806260173077",
   "metadata": {},
   "source": [
    "In this phase, we use a heatmap to identify the areas with the most concentration of pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d73aa-a5ef-4af6-a25d-053eec746035",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <th><img src=\"heatmap1.jpg\" width = 300></th>\n",
    "    <th><img src=\"heatmap2.jpg\" width = 300></th>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a8f9f-23ac-40cb-ba4d-c97ff3f245b3",
   "metadata": {},
   "source": [
    "<center> Heatmap of pixels before and after thresholding </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2153668e-bed0-462b-a787-3861ffc34897",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa7f44-6ef6-4c83-8aa9-d4daee7c8a5d",
   "metadata": {},
   "source": [
    "## Detection of Vehicles and Bounding Box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb852ae-4af2-4ec9-833b-f85f39c68a1c",
   "metadata": {},
   "source": [
    "After the previous operations are done, and we have a heatmap of recurring pixels, we start by drawing a bounding box on the pixels detected, after that we average out nearby boxes and draw one big box:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da3c66-b438-4f98-8f89-b8afa576141d",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <th><img src=\"rawbox.jpg\" width = 500></th>\n",
    "    <th><img src=\"final.jpg\" width = 500></th>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855f875c-d38c-4149-916e-3b49bba19d78",
   "metadata": {},
   "source": [
    "<center> Final car position, after removing the unwanted pixels and averaging the boxes </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef58da8-7f7b-4583-893f-5d5331bfa96f",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778aa1e3-a184-4d2b-88a2-0b07ffe92cdc",
   "metadata": {},
   "source": [
    "Please note we couldn't include the code in the notebook, because it takes approximately 30 minutes to extract the HOG features and train the SVM Classifier, then render the video."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
